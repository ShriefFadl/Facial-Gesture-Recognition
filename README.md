# Facial-Gesture-Recognition
<b>Interacting with PC using Facial Gesture Recognition</b>

Features Extraction
Using the positions of 20 facial landmarks of each image, 19 dependent features will be exctracted by
computing Euclidean distance between the position of each facial landmark and the position of tip of nose
![Screenshot (209)](https://user-images.githubusercontent.com/13305274/76220598-733bdd00-6220-11ea-9f64-d8bedcf4cdbb.png)


Classification Algorithms
Implemented the following two learning algorithms for recognizing the facial gestures in ONE package:

1 Multilayer Perceptron --> Back-Propagation
2 Radial-Basis Function --> Least Mean Square



![Screenshot (210)](https://user-images.githubusercontent.com/13305274/76220871-de85af00-6220-11ea-9098-e017d68a2dcd.png)

The dataset is real-world data, gathered from BioID Face Database [1]. The datasetconsists of 80 gray level
images (patterns) (20 images/class) with a resolution of (384*286) pixel. Each one shows the frontal view of
a face of one out of 23 different test persons


Using the positions of 20 facial landmarks of each image, 19 dependent features will be exctracted by
computing Euclidean distance between the position of each facial landmark and the position of tip of nose
